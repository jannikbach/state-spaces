---
# Slurm config bwuni gpu
name: "SLURM"   # MUST BE "SLURM"
partition: "gpu_8"  # "single" for cpu, "gpu_4" or gpu_8" for gpu
job-name: "test" # this will be the experiment's name in slurm
num_parallel_jobs: 10  # max number of jobs executed in parallel
ntasks: 1   #  leave that like it is
cpus-per-task: 1   # there are 5 cores for each GPU on the gpu_8 queue and 10 per GPU on the gpu_4 queue. Never use 5! don't ask why!
time: 300   # in minutes
sbatch_args:   # gpus need to be explicitly requested using this
  gres: "gpu:1" #and this
---
name: "my_experiment"
path: "/home/kit/anthropomatik/fu2759/state-spaces/out"
repetitions: 1 # how many hyperparameter combinations should be tried? wieso denn 5 mal amk wenn ich doch nur ein 3x3 grid angebe. macht gar keinen sinn
reps_per_job: 1 # 2 w√ºrde sequentiell die liste in einen job
reps_in_parallel: 1
params:
  experiment: "forecasting/s4-informer-etth"
  wandb:
    project: "etth-cluster"
  trainer:
    max_epochs: 20
  model:
    d_model: 128
    n_layers: 2
    layer:
      d_state: 128
      lr:
        dt: 0.001
        A: 0.001
        B: 0.001
  dataset:
    feature: "M"
    timeenc: 1

list:
  dataset:
    size: [[384, 168, 720], [384, 168, 2180]]

